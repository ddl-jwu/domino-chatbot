{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Initialize Mlflow client\n",
    "client = get_deploy_client(os.environ[\"DOMINO_MLFLOW_DEPLOYMENTS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.predict(\n",
    "    endpoint=\"chat\",\n",
    "    inputs={ \"messages\": [\n",
    "                { \n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"\"\" If the user asks a question that is not related to Domino Data Labs, AI, or machine learning, respond with the following keyword: https://www.youtube.com/watch?v=dQw4w9WgXcQ. \n",
    "                                   Otherwise, you are a virtual assistant for Domino Data Labs and your task is to answer questions related to Domino Data Labs which includes general AI/machine learning concepts.\n",
    "                                   When answering questions, only refer to the latest version of Domino. Do not use information from older versions of Domino. \"\"\" \n",
    "                },\n",
    "                { \n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"is there a configuration option that limits the number of datasets I can have in a project\" \n",
    "                } \n",
    "            ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a configuration option in Domino Data Labs that can limit the number of datasets you can have in a project. This is typically set by the Domino administrator and can be adjusted based on the needs of your organization. However, it's important to note that having too many datasets in a single project can make it difficult to manage and could potentially impact performance. It's generally recommended to keep the number of datasets in a project to a manageable level.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.predict(\n",
    "    endpoint=\"chat\",\n",
    "    inputs={ \"messages\": [\n",
    "                { \n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"\"\" If the user asks a question that is not related to Domino Data Labs, AI, or machine learning, respond with the following keyword: https://www.youtube.com/watch?v=dQw4w9WgXcQ. \n",
    "                                   Otherwise, you are a virtual assistant for Domino Data Labs and your task is to answer questions related to Domino Data Labs which includes general AI/machine learning concepts.\n",
    "                                   When answering questions, only refer to the latest version of Domino. Do not use information from older versions of Domino. \"\"\" \n",
    "                },\n",
    "                { \n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": \"what is the configuration option to limit the number of datasets in a project\" \n",
    "                } \n",
    "            ]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the latest version of Domino, there isn't a direct configuration option to limit the number of datasets in a project. However, you can manage your data and resources effectively by using Domino's project management and collaboration features. You can also use the Domino API to create custom scripts for managing your datasets. If you need more specific control over your resources, I would recommend reaching out to Domino's support team for further assistance.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "BAD_REQUEST: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for integer: \"chatbot-app\"\nLINE 3: WHERE experiments.experiment_id = 'chatbot-app' AND experime...\n                                          ^\n\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage, experiments.creation_time AS experiments_creation_time, experiments.last_update_time AS experiments_last_update_time \nFROM experiments \nWHERE experiments.experiment_id = %(experiment_id_1)s AND experiments.lifecycle_stage IN (%(lifecycle_stage_1_1)s, %(lifecycle_stage_1_2)s)]\n[parameters: {'experiment_id_1': 'chatbot-app', 'lifecycle_stage_1_1': 'active', 'lifecycle_stage_1_2': 'deleted'}]\n(Background on this error at: https://sqlalche.me/e/20/9h9h)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m      8\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m      9\u001b[0m     endpoint\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     inputs\u001b[39m=\u001b[39m{ \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     },\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m output \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mstart_run(experiment_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mchatbot-app\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m     26\u001b[0m   mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39msystem_prompt\u001b[39m\u001b[39m\"\u001b[39m, system_prompt)\n\u001b[1;32m     27\u001b[0m   mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39muser_input\u001b[39m\u001b[39m\"\u001b[39m, user_input)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/tracking/fluent.py:374\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    370\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[39m=\u001b[39m run_name\n\u001b[1;32m    372\u001b[0m     resolved_tags \u001b[39m=\u001b[39m context_registry\u001b[39m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[0;32m--> 374\u001b[0m     active_run_obj \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    375\u001b[0m         experiment_id\u001b[39m=\u001b[39;49mexp_id_for_run,\n\u001b[1;32m    376\u001b[0m         tags\u001b[39m=\u001b[39;49mresolved_tags,\n\u001b[1;32m    377\u001b[0m         run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m log_system_metrics \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[39m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     log_system_metrics \u001b[39m=\u001b[39m MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\u001b[39m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/tracking/client.py:339\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_run\u001b[39m(\n\u001b[1;32m    289\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    290\u001b[0m     experiment_id: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m     run_name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    294\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[1;32m    295\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m        status: RUNNING\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mcreate_run(experiment_id, start_time, tags, run_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:132\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m# Extract user from tags\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m# in a later release.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m user_id \u001b[39m=\u001b[39m tags\u001b[39m.\u001b[39mget(MLFLOW_USER, \u001b[39m\"\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    133\u001b[0m     experiment_id\u001b[39m=\u001b[39;49mexperiment_id,\n\u001b[1;32m    134\u001b[0m     user_id\u001b[39m=\u001b[39;49muser_id,\n\u001b[1;32m    135\u001b[0m     start_time\u001b[39m=\u001b[39;49mstart_time \u001b[39mor\u001b[39;49;00m get_current_time_millis(),\n\u001b[1;32m    136\u001b[0m     tags\u001b[39m=\u001b[39;49m[RunTag(key, value) \u001b[39mfor\u001b[39;49;00m (key, value) \u001b[39min\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mitems()],\n\u001b[1;32m    137\u001b[0m     run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    138\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:178\u001b[0m, in \u001b[0;36mRestStore.create_run\u001b[0;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    168\u001b[0m tag_protos \u001b[39m=\u001b[39m [tag\u001b[39m.\u001b[39mto_proto() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags]\n\u001b[1;32m    169\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[1;32m    170\u001b[0m     CreateRun(\n\u001b[1;32m    171\u001b[0m         experiment_id\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(experiment_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m )\n\u001b[0;32m--> 178\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(CreateRun, req_body)\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m Run\u001b[39m.\u001b[39mfrom_proto(response_proto\u001b[39m.\u001b[39mrun)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:219\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    217\u001b[0m     call_kwargs[\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m json_body\n\u001b[1;32m    218\u001b[0m     response \u001b[39m=\u001b[39m http_request(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 219\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    220\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    221\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:151\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[0;32m--> 151\u001b[0m         \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[1;32m    152\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m         base_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    154\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed with error code \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: BAD_REQUEST: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for integer: \"chatbot-app\"\nLINE 3: WHERE experiments.experiment_id = 'chatbot-app' AND experime...\n                                          ^\n\n[SQL: SELECT experiments.experiment_id AS experiments_experiment_id, experiments.name AS experiments_name, experiments.artifact_location AS experiments_artifact_location, experiments.lifecycle_stage AS experiments_lifecycle_stage, experiments.creation_time AS experiments_creation_time, experiments.last_update_time AS experiments_last_update_time \nFROM experiments \nWHERE experiments.experiment_id = %(experiment_id_1)s AND experiments.lifecycle_stage IN (%(lifecycle_stage_1_1)s, %(lifecycle_stage_1_2)s)]\n[parameters: {'experiment_id_1': 'chatbot-app', 'lifecycle_stage_1_1': 'active', 'lifecycle_stage_1_2': 'deleted'}]\n(Background on this error at: https://sqlalche.me/e/20/9h9h)"
     ]
    }
   ],
   "source": [
    "import mlflow \n",
    "\n",
    "user_input = \"what is the configuration option to limit the number of datasets in a project\" \n",
    "system_prompt = \"\"\" If the user asks a question that is not related to Domino Data Labs, AI, or machine learning, respond with the following keyword: https://www.youtube.com/watch?v=dQw4w9WgXcQ. \n",
    "                    Otherwise, you are a virtual assistant for Domino Data Labs and your task is to answer questions related to Domino Data Labs which includes general AI/machine learning concepts.\n",
    "                    When answering questions, only refer to the latest version of Domino. Do not use information from older versions of Domino. \"\"\" \n",
    "\n",
    "response = client.predict(\n",
    "    endpoint=\"chat\",\n",
    "    inputs={ \"messages\": [\n",
    "                { \n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                { \n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": user_input\n",
    "                } \n",
    "            ]\n",
    "    },\n",
    ")\n",
    "\n",
    "output = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"chatbot-app\"):\n",
    "  mlflow.log_param(\"system_prompt\", system_prompt)\n",
    "  mlflow.log_param(\"user_input\", user_input)\n",
    "  mlflow.log_param(\"output\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
